{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "a5bb89f9",
      "metadata": {
        "id": "a5bb89f9"
      },
      "source": [
        "**I think we can start here with preprocessing and building up a pipeline for classifying with a traditional model from pose estimation**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f81c3b21",
      "metadata": {
        "id": "f81c3b21"
      },
      "source": [
        "# Claases\n",
        "\n",
        "- Walking\n",
        "- Standing\n",
        "- Fast walking / jogging?\n",
        "- Running"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "5f3cb01e",
      "metadata": {
        "id": "5f3cb01e",
        "outputId": "10f27bc7-44ae-49bc-9208-68fc4756254c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Colab cache for faster access to the 'hmdb51' dataset.\n",
            "Path to dataset files: /kaggle/input/hmdb51\n"
          ]
        }
      ],
      "source": [
        "# import kagglehub\n",
        "# Download latest version from kagglehub:\n",
        "\n",
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "\n",
        "path = kagglehub.dataset_download(\"easonlll/hmdb51\")\n",
        "\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import and Conf"
      ],
      "metadata": {
        "id": "a8RG3NZ_8HTI"
      },
      "id": "a8RG3NZ_8HTI"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras import layers, models, applications\n",
        "\n",
        "DATASET_PATH = path + \"/HMDB51\"\n",
        "\n",
        "TARGET_CLASSES = [\"run\", \"walk\", \"stand\"]\n",
        "FRAME_COUNT = 16       # Number of frames per video to sample\n",
        "IMAGE_SIZE = (224, 224)\n",
        "BATCH_SIZE = 8         # Keep small for Colab (8 or 16)"
      ],
      "metadata": {
        "id": "mPRI6iRP73nL"
      },
      "id": "mPRI6iRP73nL",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Discovery"
      ],
      "metadata": {
        "id": "fKzzCB548MxP"
      },
      "id": "fKzzCB548MxP"
    },
    {
      "cell_type": "code",
      "source": [
        "def gather_sample_dirs(dataset_root, target_classes):\n",
        "    sample_paths = []\n",
        "    sample_labels = []\n",
        "    class_map = {cls: i for i, cls in enumerate(target_classes)}\n",
        "\n",
        "    print(f\"Scanning directory: {dataset_root}\")\n",
        "\n",
        "    for class_name in target_classes:\n",
        "        class_dir = os.path.join(dataset_root, class_name)\n",
        "\n",
        "        if not os.path.isdir(class_dir):\n",
        "            print(f\"Warning: Class folder '{class_name}' NOT found at {class_dir}\")\n",
        "            continue\n",
        "\n",
        "        label_id = class_map[class_name]\n",
        "\n",
        "        # In this dataset version, every video is a folder of images\n",
        "        # We loop through those folders\n",
        "        items = os.listdir(class_dir)\n",
        "        for item in items:\n",
        "            item_path = os.path.join(class_dir, item)\n",
        "            if os.path.isdir(item_path):\n",
        "                sample_paths.append(item_path)\n",
        "                sample_labels.append(label_id)\n",
        "\n",
        "    sample_paths = np.array(sample_paths)\n",
        "    sample_labels = np.array(sample_labels)\n",
        "\n",
        "    print(f\"\\n--- RESULTS ---\")\n",
        "    print(f\"Total samples found: {len(sample_paths)}\")\n",
        "    if len(sample_paths) > 0:\n",
        "        print(f\"Example path: {sample_paths[0]}\")\n",
        "        print(f\"Example label: {sample_labels[0]} ({target_classes[sample_labels[0]]})\")\n",
        "\n",
        "    return sample_paths, sample_labels\n",
        "\n",
        "# Execute the search\n",
        "X_all, y_all = gather_sample_dirs(DATASET_PATH, TARGET_CLASSES)"
      ],
      "metadata": {
        "id": "xScIW9bW8Nny",
        "outputId": "dc665296-7c92-4d3e-bde7-23c648e6f3bc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "xScIW9bW8Nny",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scanning directory: /kaggle/input/hmdb51/HMDB51\n",
            "\n",
            "--- RESULTS ---\n",
            "Total samples found: 934\n",
            "Example path: /kaggle/input/hmdb51/HMDB51/run/THE_PROTECTOR_run_f_cm_np1_le_med_42\n",
            "Example label: 0 (run)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Split data"
      ],
      "metadata": {
        "id": "kYpOGcPJ82oU"
      },
      "id": "kYpOGcPJ82oU"
    },
    {
      "cell_type": "code",
      "source": [
        "if len(X_all) == 0:\n",
        "    print(\"STOP: No data found. Check your path in Cell 1.\")\n",
        "else:\n",
        "    # Stratify ensures we have equal amounts of run/walk/stand in training and validation\n",
        "    X_train, X_val, y_train, y_val = train_test_split(\n",
        "        X_all, y_all,\n",
        "        test_size=0.2,\n",
        "        stratify=y_all,\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "    print(f\"Training samples: {len(X_train)}\")\n",
        "    print(f\"Validation samples: {len(X_val)}\")"
      ],
      "metadata": {
        "id": "fybu7-fJ84K-"
      },
      "id": "fybu7-fJ84K-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "37eca5ed",
      "metadata": {
        "id": "37eca5ed",
        "outputId": "e88d464c-ceb7-49f3-96f7-9993abfae0c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 388
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n",
            "\u001b[1m16705208/16705208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m,   │             \u001b[38;5;34m0\u001b[0m │\n",
              "│                                 │ \u001b[38;5;34m3\u001b[0m)                     │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ time_distributed                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m1280\u001b[0m) │     \u001b[38;5;34m4,049,571\u001b[0m │\n",
              "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ time_distributed_1              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m1280\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling1d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │         \u001b[38;5;34m3,843\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>,   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│                                 │ <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                     │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ time_distributed                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>) │     <span style=\"color: #00af00; text-decoration-color: #00af00\">4,049,571</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ time_distributed_1              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling1d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,843</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,053,414\u001b[0m (15.46 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,053,414</span> (15.46 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,843\u001b[0m (15.01 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,843</span> (15.01 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m4,049,571\u001b[0m (15.45 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,049,571</span> (15.45 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, applications\n",
        "\n",
        "def build_feature_pooling_model(num_classes=3, frame_count=16, image_size=224):\n",
        "    \"\"\"\n",
        "    Replicates the 'CNN Feature Extraction + SoftMax' approach.\n",
        "    It treats the video as a 'bag of frames' by averaging features over time.\n",
        "    \"\"\"\n",
        "\n",
        "    # 1. Input: (Batch, Frames, Height, Width, Channels)\n",
        "    video_input = layers.Input(shape=(frame_count, image_size, image_size, 3))\n",
        "\n",
        "    # 2. Feature Extractor: EfficientNetB0\n",
        "    base_cnn = applications.EfficientNetB0(\n",
        "        weights='imagenet',\n",
        "        include_top=False,\n",
        "        input_shape=(image_size, image_size, 3)\n",
        "    )\n",
        "    base_cnn.trainable = False\n",
        "\n",
        "    # 3. Apply CNN to every frame\n",
        "    # Output Shape: (Batch, Frames, 7, 7, 1280)\n",
        "    encoded_frames = layers.TimeDistributed(base_cnn)(video_input)\n",
        "\n",
        "    # 4. Spatial Pooling (Standard Image Step)\n",
        "    # Average the 7x7 pixels of each frame.\n",
        "    # Output Shape: (Batch, Frames, 1280)\n",
        "    frame_features = layers.TimeDistributed(layers.GlobalAveragePooling2D())(encoded_frames)\n",
        "\n",
        "    # 5. Temporal Pooling (The 'Replication' Step)\n",
        "    # instead of an LSTM, we just AVERAGE the features across the 'Frames' dimension.\n",
        "    # This creates one summary vector for the whole video.\n",
        "    # Output Shape: (Batch, 1280)\n",
        "    video_summary = layers.GlobalAveragePooling1D()(frame_features)\n",
        "\n",
        "    # 6. Classification \"with the help of SoftMax layer\"\n",
        "    output = layers.Dense(num_classes, activation='softmax')(video_summary)\n",
        "\n",
        "    # Compile\n",
        "    model = models.Model(inputs=video_input, outputs=output)\n",
        "    model.compile(\n",
        "        optimizer='adam',\n",
        "        loss='sparse_categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    return model\n",
        "\n",
        "# Instantiate\n",
        "model = build_feature_pooling_model(num_classes=3)\n",
        "model.summary()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}